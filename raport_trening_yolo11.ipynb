{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0fa693",
   "metadata": {},
   "source": [
    "## 1. Wprowadzenie\n",
    "\n",
    "### 1.1 Cel Projektu\n",
    "Celem projektu było wytrenowanie modelu detekcji obiektów YOLO11n do automatycznej klasyfikacji śmieci na 6 kategorii:\n",
    "- **BIODEGRADABLE** (biodegradowalne)\n",
    "- **CARDBOARD** (tektura)\n",
    "- **GLASS** (szkło)\n",
    "- **METAL** (metal)\n",
    "- **PAPER** (papier)\n",
    "- **PLASTIC** (plastik)\n",
    "\n",
    "### 1.2 Motywacja\n",
    "Automatyczna klasyfikacja odpadów jest kluczowa dla efektywnego systemu recyklingu i zarządzania odpadami. Model wizyjny może wspierać sortowanie śmieci w czasie rzeczywistym.\n",
    "\n",
    "### 1.3 Architektura YOLO11\n",
    "YOLO (You Only Look Once) to rodzina modeli do detekcji obiektów typu \"single-shot detector\". Wersja YOLO11n (nano) to najmniejszy i najszybszy wariant, zoptymalizowany pod kątem niskiego zużycia zasobów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0da479",
   "metadata": {},
   "source": [
    "## 2. Dataset\n",
    "\n",
    "### 2.1 Źródło Danych\n",
    "Dataset pochodzi z platformy **Roboflow**:\n",
    "- **Nazwa projektu**: garbage-classification-3\n",
    "- **Wersja**: 2\n",
    "- **Licencja**: CC BY 4.0\n",
    "- **URL**: https://universe.roboflow.com/material-identification/garbage-classification-3/dataset/2\n",
    "\n",
    "### 2.2 Struktura Datasetu\n",
    "Dataset podzielony na 3 zbiory:\n",
    "- **Training set** (`train/images/`): ~1000+ obrazów\n",
    "- **Validation set** (`valid/images/`): ~600+ obrazów\n",
    "- **Test set** (`test/images/`): ~500+ obrazów\n",
    "\n",
    "### 2.3 Format Anotacji\n",
    "Format YOLO: każdy obraz ma odpowiadający plik `.txt` z etykietami w formacie:\n",
    "```\n",
    "<class_id> <x_center> <y_center> <width> <height>\n",
    "```\n",
    "gdzie współrzędne są znormalizowane do zakresu [0, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6cfd2",
   "metadata": {},
   "source": [
    "## 3. Konfiguracja Treningu\n",
    "\n",
    "### 3.1 Parametry Modelu\n",
    "```yaml\n",
    "Model: yolo11n.pt (pretrained)\n",
    "Task: detect (object detection)\n",
    "Device: mps (Apple Silicon GPU)\n",
    "```\n",
    "\n",
    "### 3.2 Hiperparametry Treningu\n",
    "```yaml\n",
    "Epochs: 30\n",
    "Image size: 320x320 pixels\n",
    "Batch size: -1 (auto)\n",
    "Optimizer: AdamW\n",
    "Learning rate (lr0): 0.01\n",
    "Learning rate final (lrf): 0.01\n",
    "Momentum: 0.937\n",
    "Weight decay: 0.0005\n",
    "Patience: 5 (early stopping)\n",
    "```\n",
    "\n",
    "### 3.3 Data Augmentation\n",
    "```yaml\n",
    "HSV-H: 0.015 (hue augmentation)\n",
    "HSV-S: 0.7 (saturation)\n",
    "HSV-V: 0.4 (value/brightness)\n",
    "Translate: 0.1 (10% translation)\n",
    "Scale: 0.5 (50% scale variation)\n",
    "Horizontal flip: 0.5 (50% probability)\n",
    "Mosaic: 1.0 (always enabled)\n",
    "```\n",
    "\n",
    "### 3.4 Validation Strategy\n",
    "**Uwaga**: Parametr `val: false` oznacza, że walidacja była przeprowadzona **tylko po zakończeniu wszystkich epok**, nie po każdej epoce z osobna."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deee8709",
   "metadata": {},
   "source": [
    "## 4. Implementacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalacja bibliotek (jeśli potrzebne)\n",
    "# !pip install ultralytics pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "295b622b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "# Konfiguracja wykresów\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd0d01c",
   "metadata": {},
   "source": [
    "### 4.1 Kod Treningu (uproszczony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0765edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Uwaga: Ten kod pokazuje strukturę, faktyczny trening był już wykonany\n",
    "# z parametrami zapisanymi w args.yaml\n",
    "\n",
    "# Load pretrained YOLO11n model\n",
    "# model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Train the model\n",
    "# train_results = model.train(\n",
    "#     data=\"data.yaml\",\n",
    "#     epochs=30,\n",
    "#     imgsz=320,\n",
    "#     device=\"mps\",\n",
    "#     optimizer=\"AdamW\",\n",
    "#     lr0=0.01,\n",
    "#     patience=5\n",
    "# )\n",
    "\n",
    "# Validate\n",
    "# metrics = model.val()\n",
    "\n",
    "# Export to ONNX\n",
    "# model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd01447",
   "metadata": {},
   "source": [
    "## 5. Analiza Wyników Treningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie wyników z pliku CSV\n",
    "results_path = r\"c:\\Users\\fnubu\\Documents\\code\\STUDIA\\PRIAD\\GarbageClassification\\GARBAGE CLASSIFICATION 3\\runs\\detect\\train\\results.csv\"\n",
    "df = pd.read_csv(results_path)\n",
    "\n",
    "# Wyświetlenie pierwszych i ostatnich epok\n",
    "print(\"=== Pierwsze 3 epoki ===\")\n",
    "print(df[['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss']].head(3))\n",
    "print(\"\\n=== Ostatnie 3 epoki ===\")\n",
    "print(df[['epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss']].tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545abfab",
   "metadata": {},
   "source": [
    "### 5.1 Progres Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d869d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres strat treningowych\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Box Loss\n",
    "axes[0].plot(df['epoch'], df['train/box_loss'], marker='o', linewidth=2, color='#2E86AB')\n",
    "axes[0].set_title('Box Loss (Localization)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Classification Loss\n",
    "axes[1].plot(df['epoch'], df['train/cls_loss'], marker='s', linewidth=2, color='#A23B72')\n",
    "axes[1].set_title('Classification Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# DFL Loss\n",
    "axes[2].plot(df['epoch'], df['train/dfl_loss'], marker='^', linewidth=2, color='#F18F01')\n",
    "axes[2].set_title('DFL Loss (Distribution Focal Loss)', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Loss')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_losses.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ebc96f",
   "metadata": {},
   "source": [
    "### 5.2 Interpretacja Strat\n",
    "\n",
    "**Box Loss (Localization Loss)**:\n",
    "- Epoka 1: 1.688 → Epoka 30: 1.252\n",
    "- Spadek o ~26% - model poprawia lokalizację bounding boxes\n",
    "\n",
    "**Classification Loss**:\n",
    "- Epoka 1: 2.344 → Epoka 30: 1.334\n",
    "- Spadek o ~43% - najlepszy progres, model uczy się rozróżniać klasy\n",
    "\n",
    "**DFL Loss (Distribution Focal Loss)**:\n",
    "- Epoka 1: 1.505 → Epoka 30: 1.275\n",
    "- Spadek o ~15% - model precyzuje przewidywania rozkładów\n",
    "\n",
    "✅ **Wniosek**: Wszystkie straty maleją konsekwentnie - model się uczył poprawnie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14da6a5",
   "metadata": {},
   "source": [
    "### 5.3 Learning Rate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b747d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres learning rate\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['epoch'], df['lr/pg0'], marker='o', linewidth=2, color='#06A77D', label='Learning Rate')\n",
    "plt.title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('learning_rate.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Learning rate początkowy: {df['lr/pg0'].iloc[0]:.6f}\")\n",
    "print(f\"Learning rate końcowy: {df['lr/pg0'].iloc[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2293f7",
   "metadata": {},
   "source": [
    "## 6. Metryki Walidacyjne\n",
    "\n",
    "### 6.1 Ostateczne Wyniki (Epoka 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdd185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyciągnięcie metryk z ostatniej epoki (jedyna z walidacją)\n",
    "final_metrics = df.iloc[-1]\n",
    "\n",
    "metrics_dict = {\n",
    "    'Metric': ['Precision', 'Recall', 'mAP@0.5', 'mAP@0.5:0.95', 'Val Box Loss', 'Val Cls Loss', 'Val DFL Loss'],\n",
    "    'Value': [\n",
    "        final_metrics['metrics/precision(B)'],\n",
    "        final_metrics['metrics/recall(B)'],\n",
    "        final_metrics['metrics/mAP50(B)'],\n",
    "        final_metrics['metrics/mAP50-95(B)'],\n",
    "        final_metrics['val/box_loss'],\n",
    "        final_metrics['val/cls_loss'],\n",
    "        final_metrics['val/dfl_loss']\n",
    "    ]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_dict)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OSTATECZNE METRYKI WALIDACYJNE (Epoka 30)\")\n",
    "print(\"=\"*50)\n",
    "print(metrics_df.to_string(index=False))\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bbd267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wizualizacja metryk\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "metrics_to_plot = metrics_df.iloc[:4]  # Tylko precision, recall, mAP50, mAP50-95\n",
    "colors = ['#2E86AB', '#A23B72', '#F18F01', '#06A77D']\n",
    "\n",
    "bars = ax.barh(metrics_to_plot['Metric'], metrics_to_plot['Value'], color=colors)\n",
    "ax.set_xlabel('Score', fontsize=12)\n",
    "ax.set_title('Validation Metrics (Epoch 30)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 1)\n",
    "\n",
    "# Dodanie wartości na końcu słupków\n",
    "for i, (metric, value) in enumerate(zip(metrics_to_plot['Metric'], metrics_to_plot['Value'])):\n",
    "    ax.text(value + 0.02, i, f'{value:.3f}', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('validation_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a566d9",
   "metadata": {},
   "source": [
    "### 6.2 Interpretacja Metryk\n",
    "\n",
    "**Precision: 0.282 (28.2%)**\n",
    "- Z wszystkich obiektów, które model wykrył, tylko 28% było prawidłowo sklasyfikowanych\n",
    "- **Problem**: Dużo false positives (model \"widzi\" śmieci tam, gdzie ich nie ma lub błędnie je klasyfikuje)\n",
    "\n",
    "**Recall: 0.082 (8.2%)**\n",
    "- Model znalazł tylko 8% wszystkich obiektów obecnych w obrazach\n",
    "- **Problem**: Bardzo dużo false negatives (model pomija większość śmieci)\n",
    "\n",
    "**mAP@0.5: 0.084 (8.4%)**\n",
    "- Mean Average Precision przy IoU threshold 0.5\n",
    "- Wartość poniżej 0.1 = **bardzo słaba wydajność**\n",
    "- Standardowo oczekiwalibyśmy mAP50 > 0.5 dla przyzwoitego modelu\n",
    "\n",
    "**mAP@0.5:0.95: 0.057 (5.7%)**\n",
    "- Średnia z mAP przy progach IoU od 0.5 do 0.95\n",
    "- Jeszcze niższa wartość potwierdza słabą lokalizację obiektów\n",
    "\n",
    "⚠️ **Podsumowanie**: Model wymaga znaczącej poprawy - obecne wyniki są poniżej użytecznego poziomu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ebdd3",
   "metadata": {},
   "source": [
    "## 7. Dyskusja i Analiza Problemów\n",
    "\n",
    "### 7.1 Zidentyfikowane Problemy\n",
    "\n",
    "#### 1. **Słabe Wyniki Walidacyjne**\n",
    "Główny problem: mAP@0.5 = 8.4% to wynik nieużyteczny w praktyce.\n",
    "\n",
    "**Możliwe przyczyny**:\n",
    "\n",
    "**a) Zbyt mały rozmiar obrazów (320px)**\n",
    "- Standardowy rozmiar dla YOLO to 640px\n",
    "- 320px = 4x mniej pikseli = utrata szczegółów obiektów\n",
    "- Szczególnie problematyczne dla małych obiektów\n",
    "\n",
    "**b) Model Nano (YOLO11n)**\n",
    "- Najmniejszy wariant YOLOv11\n",
    "- Szybki, ale najmniej dokładny\n",
    "- Lepsze wyniki: YOLO11s (small), YOLO11m (medium) lub YOLO11l (large)\n",
    "\n",
    "**c) Za mało epok (30)**\n",
    "- Training loss wciąż spadał na epoce 30\n",
    "- Model prawdopodobnie nie osiągnął pełnej zbieżności\n",
    "- Rekomendacja: 100-200 epok dla złożonych datasetsów\n",
    "\n",
    "**d) Brak walidacji międzyepokowej**\n",
    "- `val: false` = brak monitoringu podczas treningu\n",
    "- Nie można było obserwować overfittingu\n",
    "- Brak informacji o najlepszym checkpoincie\n",
    "\n",
    "**e) Możliwa niezrównoważona dystrybucja klas**\n",
    "- W katalogu `train/images/` zauważono przewagę plików z klasą PLASTIC\n",
    "- Niezbalansowany dataset może powodować bias modelu\n",
    "\n",
    "#### 2. **Rozbieżność Kodu i Faktycznych Parametrów**\n",
    "- Plik `model.py` pokazuje: `epochs=1, imgsz=640, device=\"cpu\"`\n",
    "- Faktyczne parametry (z `args.yaml`): `epochs=30, imgsz=320, device=\"mps\"`\n",
    "- **Wniosek**: Kod w `model.py` to tylko przykład, faktyczny trening był uruchomiony z innych parametrów (prawdopodobnie CLI lub inny skrypt)\n",
    "\n",
    "### 7.2 Rekomendacje na Przyszłość\n",
    "\n",
    "**Aby poprawić wyniki, zalecam**:\n",
    "\n",
    "1. **Zwiększyć rozmiar obrazów do 640px**\n",
    "   ```python\n",
    "   model.train(data=\"data.yaml\", epochs=100, imgsz=640, ...)\n",
    "   ```\n",
    "\n",
    "2. **Użyć większego modelu (YOLO11s lub YOLO11m)**\n",
    "   ```python\n",
    "   model = YOLO(\"yolo11s.pt\")  # lub yolo11m.pt\n",
    "   ```\n",
    "\n",
    "3. **Wydłużyć trening do 100-200 epok**\n",
    "   ```python\n",
    "   epochs=100\n",
    "   ```\n",
    "\n",
    "4. **Włączyć walidację po każdej epoce**\n",
    "   ```python\n",
    "   val=True  # w parametrach treningu\n",
    "   ```\n",
    "\n",
    "5. **Sprawdzić balans klas w datasecie**\n",
    "   ```python\n",
    "   # Analiza dystrybucji klas\n",
    "   from collections import Counter\n",
    "   import glob\n",
    "   \n",
    "   labels = []\n",
    "   for file in glob.glob('train/labels/*.txt'):\n",
    "       with open(file) as f:\n",
    "           labels.extend([int(line.split()[0]) for line in f])\n",
    "   \n",
    "   print(Counter(labels))\n",
    "   ```\n",
    "\n",
    "6. **Rozważyć class weights dla niezbalansowanych klas**\n",
    "\n",
    "7. **Użyć większego learning rate warmup**\n",
    "   ```python\n",
    "   warmup_epochs=5  # zamiast 3\n",
    "   ```\n",
    "\n",
    "8. **Eksperymentować z augmentacjami**\n",
    "   - Możliwe zwiększenie `mosaic`, `mixup`, `copy_paste`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35926ef8",
   "metadata": {},
   "source": [
    "## 8. Wnioski\n",
    "\n",
    "### 8.1 Podsumowanie Treningu\n",
    "\n",
    "✅ **Pozytywne aspekty**:\n",
    "- Model został pomyślnie wytrenowany przez 30 epok\n",
    "- Training loss konsekwentnie malał we wszystkich składowych\n",
    "- Infrastruktura treningu działa poprawnie (MPS, augmentacje)\n",
    "- Dataset jest poprawnie sformatowany (Roboflow YOLO format)\n",
    "- Eksport do ONNX dostępny dla deployment\n",
    "\n",
    "❌ **Problemy do rozwiązania**:\n",
    "- **Bardzo słabe metryki walidacyjne** (mAP@0.5 = 8.4%)\n",
    "- Recall 8.2% = model pomija 92% obiektów\n",
    "- Model wymaga gruntownej poprawy przed użyciem praktycznym\n",
    "- Możliwa niezrównoważona dystrybucja klas w datasecie\n",
    "\n",
    "### 8.2 Dalsze Kroki\n",
    "\n",
    "**Krótkoterminowe (następny trening)**:\n",
    "1. Zwiększyć rozmiar obrazów do 640px\n",
    "2. Użyć YOLO11s zamiast YOLO11n\n",
    "3. Trenować przez 100 epok z walidacją co epokę\n",
    "4. Monitorować metryki i zapisywać checkpointy\n",
    "\n",
    "**Średnioterminowe (optymalizacja)**:\n",
    "1. Analiza datasetu: rozkład klas, jakość anotacji\n",
    "2. Eksperyment z różnymi augmentacjami\n",
    "3. Transfer learning z modeli trenowanych na podobnych datasetsach\n",
    "4. Ensemble z większymi modelami\n",
    "\n",
    "**Długoterminowe (deployment)**:\n",
    "1. Osiągnąć mAP@0.5 > 0.5 przed wdrożeniem\n",
    "2. Testy w realnych warunkach\n",
    "3. Continuous training z nowymi danymi\n",
    "4. Monitoring production metrics\n",
    "\n",
    "### 8.3 Nauka z Projektu\n",
    "\n",
    "Ten projekt pokazał:\n",
    "- **Znaczenie hiperparametrów**: Rozmiar obrazów i wielkość modelu mają kluczowy wpływ\n",
    "- **Potrzebę monitoringu**: Walidacja tylko na końcu nie pozwala na wczesne wykrycie problemów\n",
    "- **Wartość datasetu**: Jakość i balans danych jest fundamentalna\n",
    "- **Iteracyjność deep learning**: Pierwszy model rzadko jest optymalny\n",
    "\n",
    "---\n",
    "\n",
    "**Model wymaga retraininingu z poprawionymi parametrami przed użyciem w produkcji.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8602d16c",
   "metadata": {},
   "source": [
    "## 9. Bibliografia i Źródła\n",
    "\n",
    "1. **Ultralytics YOLOv11 Documentation**  \n",
    "   https://docs.ultralytics.com/\n",
    "\n",
    "2. **Roboflow Dataset**  \n",
    "   https://universe.roboflow.com/material-identification/garbage-classification-3/dataset/2\n",
    "\n",
    "3. **YOLOv11 Paper** (jeśli dostępny)  \n",
    "   [Link do publikacji]\n",
    "\n",
    "4. **Mean Average Precision (mAP) Explained**  \n",
    "   [Dodaj źródło teoretyczne]\n",
    "\n",
    "5. **Object Detection Metrics Guide**  \n",
    "   [Dodaj źródło]\n",
    "\n",
    "---\n",
    "\n",
    "**Appendix: Pliki Projektu**\n",
    "- `data.yaml`: Konfiguracja datasetu\n",
    "- `args.yaml`: Kompletne parametry treningu\n",
    "- `results.csv`: Historia metryk treningowych\n",
    "- `weights/best.pt`: Najlepszy checkpoint modelu\n",
    "- `weights/last.pt`: Ostatni checkpoint (epoka 30)\n",
    "- `weights/best.onnx`: Model w formacie ONNX do deploymentu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
